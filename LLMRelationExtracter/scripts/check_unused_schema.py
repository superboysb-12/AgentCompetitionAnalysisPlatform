#!/usr/bin/env python3
"""
æ£€æµ‹é…ç½®ä¸­å®šä¹‰ä½†æœªåœ¨æå–ç»“æœä¸­ä½¿ç”¨çš„å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹
"""

import json
import yaml
import argparse
import os
from typing import Dict, Set, List
from collections import Counter


def load_config(config_path: str) -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def load_extraction_results(result_path: str) -> Dict:
    """åŠ è½½ä¸‰å…ƒç»„æå–ç»“æœ"""
    with open(result_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_used_types(results: Dict) -> tuple[Set[str], Set[str]]:
    """ä»æå–ç»“æœä¸­æå–å·²ä½¿ç”¨çš„å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹"""
    used_entity_types = set()
    used_relation_types = set()

    # å°è¯•ä¸åŒçš„ç»“æœæ ¼å¼
    triplets = []

    # æ ¼å¼1: ç›´æ¥æ˜¯tripletsæ•°ç»„
    if 'triplets' in results:
        if isinstance(results['triplets'], list):
            triplets = results['triplets']
        elif isinstance(results['triplets'], dict):
            # æ ¼å¼2: tripletsæ˜¯å­—å…¸ï¼ŒåŒ…å«in_config/out_of_config/all
            triplets = results['triplets'].get('all', [])

    # æ ¼å¼3: ç›´æ¥æ˜¯æ•°ç»„
    if isinstance(results, list):
        triplets = results

    for triplet in triplets:
        used_entity_types.add(triplet.get('subject_type', ''))
        used_entity_types.add(triplet.get('object_type', ''))
        used_relation_types.add(triplet.get('relation', ''))

    # ç§»é™¤ç©ºå­—ç¬¦ä¸²
    used_entity_types.discard('')
    used_relation_types.discard('')

    return used_entity_types, used_relation_types


def analyze_schema_coverage(config: Dict, results: Dict) -> Dict:
    """åˆ†æSchemaè¦†ç›–æƒ…å†µ"""
    # è·å–é…ç½®ä¸­å®šä¹‰çš„ç±»å‹
    config_entity_types = set(config.get('entity_types', {}).keys())
    config_relation_types = set(config.get('relation_types', {}).keys())

    # è·å–å®é™…ä½¿ç”¨çš„ç±»å‹
    used_entity_types, used_relation_types = extract_used_types(results)

    # è®¡ç®—æœªä½¿ç”¨çš„ç±»å‹
    unused_entity_types = config_entity_types - used_entity_types
    unused_relation_types = config_relation_types - used_relation_types

    # è®¡ç®—é…ç½®å¤–çš„ç±»å‹ï¼ˆæ–°å‘ç°çš„ç±»å‹ï¼‰
    new_entity_types = used_entity_types - config_entity_types
    new_relation_types = used_relation_types - config_relation_types

    # ç»Ÿè®¡æ¯ä¸ªç±»å‹çš„ä½¿ç”¨é¢‘ç‡
    entity_type_counts = Counter()
    relation_type_counts = Counter()

    triplets = []
    if 'triplets' in results:
        if isinstance(results['triplets'], list):
            triplets = results['triplets']
        elif isinstance(results['triplets'], dict):
            triplets = results['triplets'].get('all', [])
    if isinstance(results, list):
        triplets = results

    for triplet in triplets:
        entity_type_counts[triplet.get('subject_type', '')] += 1
        entity_type_counts[triplet.get('object_type', '')] += 1
        relation_type_counts[triplet.get('relation', '')] += 1

    return {
        'config_entity_types': config_entity_types,
        'config_relation_types': config_relation_types,
        'used_entity_types': used_entity_types,
        'used_relation_types': used_relation_types,
        'unused_entity_types': unused_entity_types,
        'unused_relation_types': unused_relation_types,
        'new_entity_types': new_entity_types,
        'new_relation_types': new_relation_types,
        'entity_type_counts': dict(entity_type_counts),
        'relation_type_counts': dict(relation_type_counts),
        'statistics': {
            'total_config_entities': len(config_entity_types),
            'total_config_relations': len(config_relation_types),
            'used_entities': len(used_entity_types),
            'used_relations': len(used_relation_types),
            'unused_entities': len(unused_entity_types),
            'unused_relations': len(unused_relation_types),
            'new_entities': len(new_entity_types),
            'new_relations': len(new_relation_types),
            'entity_coverage': f"{len(used_entity_types & config_entity_types) / len(config_entity_types) * 100:.1f}%" if config_entity_types else "N/A",
            'relation_coverage': f"{len(used_relation_types & config_relation_types) / len(config_relation_types) * 100:.1f}%" if config_relation_types else "N/A"
        }
    }


def print_analysis_report(analysis: Dict, verbose: bool = False):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("Schema ä½¿ç”¨æƒ…å†µåˆ†ææŠ¥å‘Š")
    print("=" * 80)

    stats = analysis['statistics']
    print(f"\nã€ç»Ÿè®¡æ‘˜è¦ã€‘")
    print(f"  é…ç½®å®ä½“ç±»å‹æ•°: {stats['total_config_entities']}")
    print(f"  é…ç½®å…³ç³»ç±»å‹æ•°: {stats['total_config_relations']}")
    print(f"  å®é™…ä½¿ç”¨å®ä½“ç±»å‹æ•°: {stats['used_entities']}")
    print(f"  å®é™…ä½¿ç”¨å…³ç³»ç±»å‹æ•°: {stats['used_relations']}")
    print(f"  å®ä½“ç±»å‹è¦†ç›–ç‡: {stats['entity_coverage']}")
    print(f"  å…³ç³»ç±»å‹è¦†ç›–ç‡: {stats['relation_coverage']}")
    print(f"  æœªä½¿ç”¨å®ä½“ç±»å‹æ•°: {stats['unused_entities']}")
    print(f"  æœªä½¿ç”¨å…³ç³»ç±»å‹æ•°: {stats['unused_relations']}")
    print(f"  æ–°å‘ç°å®ä½“ç±»å‹æ•°: {stats['new_entities']}")
    print(f"  æ–°å‘ç°å…³ç³»ç±»å‹æ•°: {stats['new_relations']}")

    # æœªä½¿ç”¨çš„å®ä½“ç±»å‹
    if analysis['unused_entity_types']:
        print(f"\nã€æœªä½¿ç”¨çš„å®ä½“ç±»å‹ã€‘({len(analysis['unused_entity_types'])} ä¸ª)")
        for entity_type in sorted(analysis['unused_entity_types']):
            print(f"  âŒ {entity_type}")
    else:
        print(f"\nã€æœªä½¿ç”¨çš„å®ä½“ç±»å‹ã€‘")
        print("  âœ… æ‰€æœ‰é…ç½®çš„å®ä½“ç±»å‹éƒ½å·²ä½¿ç”¨")

    # æœªä½¿ç”¨çš„å…³ç³»ç±»å‹
    if analysis['unused_relation_types']:
        print(f"\nã€æœªä½¿ç”¨çš„å…³ç³»ç±»å‹ã€‘({len(analysis['unused_relation_types'])} ä¸ª)")
        for relation_type in sorted(analysis['unused_relation_types']):
            print(f"  âŒ {relation_type}")
    else:
        print(f"\nã€æœªä½¿ç”¨çš„å…³ç³»ç±»å‹ã€‘")
        print("  âœ… æ‰€æœ‰é…ç½®çš„å…³ç³»ç±»å‹éƒ½å·²ä½¿ç”¨")

    # æ–°å‘ç°çš„ç±»å‹
    if analysis['new_entity_types']:
        print(f"\nã€æ–°å‘ç°çš„å®ä½“ç±»å‹ã€‘({len(analysis['new_entity_types'])} ä¸ª)")
        for entity_type in sorted(analysis['new_entity_types']):
            count = analysis['entity_type_counts'].get(entity_type, 0)
            print(f"  â­ {entity_type} (å‡ºç° {count} æ¬¡)")

    if analysis['new_relation_types']:
        print(f"\nã€æ–°å‘ç°çš„å…³ç³»ç±»å‹ã€‘({len(analysis['new_relation_types'])} ä¸ª)")
        for relation_type in sorted(analysis['new_relation_types']):
            count = analysis['relation_type_counts'].get(relation_type, 0)
            print(f"  â­ {relation_type} (å‡ºç° {count} æ¬¡)")

    # è¯¦ç»†ä½¿ç”¨é¢‘ç‡ï¼ˆå¦‚æœå¯ç”¨verboseï¼‰
    if verbose:
        print(f"\nã€å®ä½“ç±»å‹ä½¿ç”¨é¢‘ç‡ã€‘(Top 20)")
        entity_counts = analysis['entity_type_counts']
        sorted_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)[:20]
        for entity_type, count in sorted_entities:
            status = "âœ“" if entity_type in analysis['config_entity_types'] else "â­"
            print(f"  {status} {entity_type}: {count} æ¬¡")

        print(f"\nã€å…³ç³»ç±»å‹ä½¿ç”¨é¢‘ç‡ã€‘(Top 20)")
        relation_counts = analysis['relation_type_counts']
        sorted_relations = sorted(relation_counts.items(), key=lambda x: x[1], reverse=True)[:20]
        for relation_type, count in sorted_relations:
            status = "âœ“" if relation_type in analysis['config_relation_types'] else "â­"
            print(f"  {status} {relation_type}: {count} æ¬¡")

    print("\n" + "=" * 80)
    print("è¯´æ˜:")
    print("  âŒ - é…ç½®ä¸­å®šä¹‰ä½†æœªä½¿ç”¨çš„ç±»å‹")
    print("  âœ… - å·²ä½¿ç”¨çš„é…ç½®ç±»å‹")
    print("  â­ - æ–°å‘ç°çš„ç±»å‹(ä¸åœ¨é…ç½®ä¸­)")
    print("=" * 80 + "\n")


def save_analysis_to_json(analysis: Dict, output_path: str):
    """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
    # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
    serializable_analysis = {
        'config_entity_types': sorted(list(analysis['config_entity_types'])),
        'config_relation_types': sorted(list(analysis['config_relation_types'])),
        'used_entity_types': sorted(list(analysis['used_entity_types'])),
        'used_relation_types': sorted(list(analysis['used_relation_types'])),
        'unused_entity_types': sorted(list(analysis['unused_entity_types'])),
        'unused_relation_types': sorted(list(analysis['unused_relation_types'])),
        'new_entity_types': sorted(list(analysis['new_entity_types'])),
        'new_relation_types': sorted(list(analysis['new_relation_types'])),
        'entity_type_counts': analysis['entity_type_counts'],
        'relation_type_counts': analysis['relation_type_counts'],
        'statistics': analysis['statistics']
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(serializable_analysis, f, ensure_ascii=False, indent=2)

    print(f"âœ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description='æ£€æµ‹é…ç½®ä¸­å®šä¹‰ä½†æœªåœ¨æå–ç»“æœä¸­ä½¿ç”¨çš„Schemaç±»å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  python check_unused_schema.py -c config.yaml -r knowledge_graph.json

  # æ˜¾ç¤ºè¯¦ç»†ä½¿ç”¨é¢‘ç‡
  python check_unused_schema.py -c config.yaml -r knowledge_graph.json -v

  # ä¿å­˜åˆ†æç»“æœåˆ°JSON
  python check_unused_schema.py -c config.yaml -r knowledge_graph.json -o analysis.json
        """
    )

    parser.add_argument('-c', '--config',
                        default='config.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)')

    parser.add_argument('-r', '--results',
                        default='knowledge_graph.json',
                        help='ä¸‰å…ƒç»„æå–ç»“æœæ–‡ä»¶è·¯å¾„ (é»˜è®¤: knowledge_graph.json)')

    parser.add_argument('-o', '--output',
                        help='ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶')

    parser.add_argument('-v', '--verbose',
                        action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†çš„ä½¿ç”¨é¢‘ç‡ç»Ÿè®¡')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return 1

    if not os.path.exists(args.results):
        print(f"âŒ é”™è¯¯: ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {args.results}")
        return 1

    try:
        # åŠ è½½æ–‡ä»¶
        print(f"ğŸ“– åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
        config = load_config(args.config)

        print(f"ğŸ“– åŠ è½½æå–ç»“æœ: {args.results}")
        results = load_extraction_results(args.results)

        # åˆ†æ
        print("ğŸ” åˆ†æSchemaä½¿ç”¨æƒ…å†µ...")
        analysis = analyze_schema_coverage(config, results)

        # æ‰“å°æŠ¥å‘Š
        print_analysis_report(analysis, verbose=args.verbose)

        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            save_analysis_to_json(analysis, args.output)

        return 0

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
