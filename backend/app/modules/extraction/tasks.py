"""
CeleryçŸ¥è¯†æŠ½å–ä»»åŠ¡å®šä¹‰
"""
from celery import Task
from typing import Dict, Any, List
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

from celery_app import celery_app
from app.database import SessionLocal
from .services.extraction_service import ExtractionService
from app.config import settings

logger = logging.getLogger(__name__)


class ExtractionTask(Task):
    """æŠ½å–ä»»åŠ¡åŸºç±»"""

    def __call__(self, *args, **kwargs):
        """é‡å†™è°ƒç”¨æ–¹æ³•ï¼Œç¡®ä¿æ¯ä¸ªä»»åŠ¡éƒ½æœ‰æ•°æ®åº“ä¼šè¯"""
        with SessionLocal() as db:
            self.db = db
            return self.run(*args, **kwargs)


@celery_app.task(
    bind=True,
    base=ExtractionTask,
    name="app.tasks.extraction_tasks.extract_single_result",
    queue="extraction_queue"
)
def extract_single_result(self, result_id: int) -> Dict[str, Any]:
    """
    æŠ½å–å•ä¸ªçˆ¬å–ç»“æœ

    Args:
        result_id: çˆ¬å–ç»“æœID

    Returns:
        dict: æ‰§è¡Œç»“æœ
    """
    logger.info(f"CeleryæŠ½å–ä»»åŠ¡å¼€å§‹: result_id={result_id}, ä»»åŠ¡ID: {self.request.id}")

    try:
        extraction_service = ExtractionService(self.db)

        success, message, extraction_record_id = extraction_service.extract_from_result(result_id)

        if success:
            logger.info(f"âœ“ æŠ½å–ä»»åŠ¡å®Œæˆ: result_id={result_id}, {message}")
            return {
                'success': True,
                'result_id': result_id,
                'extraction_record_id': extraction_record_id,
                'message': message
            }
        else:
            logger.error(f"âŒ æŠ½å–ä»»åŠ¡å¤±è´¥: result_id={result_id}, {message}")
            return {
                'success': False,
                'result_id': result_id,
                'extraction_record_id': extraction_record_id,
                'message': message
            }

    except Exception as e:
        logger.error(f"âŒ æŠ½å–ä»»åŠ¡å¼‚å¸¸: result_id={result_id}, {e}")
        return {
            'success': False,
            'result_id': result_id,
            'message': str(e)
        }


@celery_app.task(
    bind=True,
    base=ExtractionTask,
    name="app.tasks.extraction_tasks.retry_failed_extractions",
    queue="extraction_queue"
)
def retry_failed_extractions(self) -> Dict[str, Any]:
    """
    é‡è¯•æ‰€æœ‰å¤±è´¥çš„æŠ½å–

    Returns:
        dict: æ‰§è¡Œç»“æœ
    """
    logger.info(f"Celeryé‡è¯•å¤±è´¥æŠ½å–ä»»åŠ¡å¼€å§‹: ä»»åŠ¡ID: {self.request.id}")

    try:
        extraction_service = ExtractionService(self.db)

        success_count, failed_count = extraction_service.retry_failed_extractions()

        logger.info(f"âœ“ é‡è¯•ä»»åŠ¡å®Œæˆ: æˆåŠŸ={success_count}, å¤±è´¥={failed_count}")

        return {
            'success': True,
            'message': 'é‡è¯•å®Œæˆ',
            'success_count': success_count,
            'failed_count': failed_count
        }

    except Exception as e:
        logger.error(f"âŒ é‡è¯•ä»»åŠ¡å¼‚å¸¸: {e}")
        return {
            'success': False,
            'message': str(e)
        }


@celery_app.task(
    bind=True,
    base=ExtractionTask,
    name="app.tasks.extraction_tasks.batch_extract_all_pending_parallel",
    queue="extraction_queue"
)
def batch_extract_all_pending_parallel(self, max_workers: int = None) -> Dict[str, Any]:
    """
    æ‰¹é‡å¹¶è¡ŒæŠ½å–æ‰€æœ‰å¾…å¤„ç†çš„çˆ¬å–ç»“æœï¼ˆä½¿ç”¨ThreadPoolExecutor + tqdmï¼‰

    æ­¤ä»»åŠ¡ä¼šï¼š
    1. è·å–æ‰€æœ‰æœªè¿›è¡Œä¿¡æ¯æŠ½å–çš„ç»“æœ
    2. ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    3. æ˜¾ç¤ºå®æ—¶è¿›åº¦æ¡ï¼ˆé€šè¿‡æ—¥å¿—ï¼‰
    4. è‡ªåŠ¨å¤„ç†é”™è¯¯å’Œé‡è¯•

    Args:
        max_workers: æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–

    Returns:
        dict: æ‰§è¡Œç»“æœï¼ŒåŒ…å«æˆåŠŸæ•°ã€å¤±è´¥æ•°ã€é”™è¯¯åˆ—è¡¨ç­‰
    """
    logger.info(f"Celeryå¹¶è¡Œæ‰¹é‡æŠ½å–ä»»åŠ¡å¼€å§‹: ä»»åŠ¡ID: {self.request.id}")

    try:
        extraction_service = ExtractionService(self.db)

        # è·å–æ‰€æœ‰å¾…æŠ½å–çš„ç»“æœ
        result_ids = extraction_service.get_pending_results(limit=None)

        if not result_ids:
            logger.info("æ²¡æœ‰å¾…æŠ½å–çš„ç»“æœ")
            return {
                'success': True,
                'message': 'æ²¡æœ‰å¾…æŠ½å–çš„ç»“æœ',
                'total': 0,
                'success_count': 0,
                'failed_count': 0,
                'errors': []
            }

        logger.info(f"æ‰¾åˆ° {len(result_ids)} ä¸ªå¾…æŠ½å–çš„ç»“æœï¼Œå‡†å¤‡å¹¶è¡Œå¤„ç†")

        # è®¾ç½®å¹¶è¡Œçº¿ç¨‹æ•°
        if max_workers is None:
            max_workers = getattr(settings, 'kg_max_workers', 10)

        success_count = 0
        failed_count = 0
        errors = []

        def process_single_result(result_id: int) -> Dict[str, Any]:
            """å¤„ç†å•ä¸ªç»“æœçš„å‡½æ•°"""
            # æ¯ä¸ªçº¿ç¨‹éœ€è¦è‡ªå·±çš„æ•°æ®åº“ä¼šè¯
            with SessionLocal() as thread_db:
                thread_service = ExtractionService(thread_db)
                success, message, extraction_record_id = thread_service.extract_from_result(result_id)

                return {
                    'result_id': result_id,
                    'success': success,
                    'message': message,
                    'extraction_record_id': extraction_record_id
                }

        # ä½¿ç”¨ThreadPoolExecutor + tqdmå¹¶è¡Œå¤„ç†
        logger.info(f"å¯ç”¨å¹¶è¡Œå¤„ç†ï¼Œçº¿ç¨‹æ•°: {max_workers}")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_result_id = {
                executor.submit(process_single_result, result_id): result_id
                for result_id in result_ids
            }

            # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š å¼€å§‹å¹¶è¡Œå¤„ç† {len(result_ids)} ä¸ªç»“æœ...")
            logger.info("=" * 80)

            # åˆ›å»ºè¿›åº¦æ¡ï¼ˆé€šè¿‡æ—¥å¿—è¾“å‡ºè¿›åº¦ä¿¡æ¯ï¼‰
            with tqdm(
                total=len(result_ids),
                desc="ğŸ”„ çŸ¥è¯†å›¾è°±æŠ½å–è¿›åº¦",
                unit="docs",
                ncols=100,
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
            ) as pbar:
                for future in as_completed(future_to_result_id):
                    result_id = future_to_result_id[future]

                    try:
                        result = future.result()

                        if result['success']:
                            success_count += 1
                            pbar.set_postfix_str(f"âœ“ {success_count} | âœ— {failed_count}")
                        else:
                            failed_count += 1
                            error_msg = f"result_id={result_id}: {result['message']}"
                            errors.append(error_msg)
                            pbar.set_postfix_str(f"âœ“ {success_count} | âœ— {failed_count}")
                            logger.error(f"âœ— {error_msg}")

                    except Exception as e:
                        failed_count += 1
                        error_msg = f"result_id={result_id}: {str(e)}"
                        errors.append(error_msg)
                        pbar.set_postfix_str(f"âœ“ {success_count} | âœ— {failed_count}")
                        logger.error(f"âœ— å¼‚å¸¸: {error_msg}")

                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.update(1)

        logger.info("=" * 80)
        logger.info(f"âœ“ å¹¶è¡Œæ‰¹é‡æŠ½å–ä»»åŠ¡å®Œæˆ")
        logger.info(f"æ€»æ•°: {len(result_ids)} | æˆåŠŸ: {success_count} | å¤±è´¥: {failed_count}")
        logger.info("=" * 80)

        return {
            'success': True,
            'message': f'å¹¶è¡Œæ‰¹é‡æŠ½å–å®Œæˆ',
            'total': len(result_ids),
            'success_count': success_count,
            'failed_count': failed_count,
            'errors': errors[:50],  # åªè¿”å›å‰50ä¸ªé”™è¯¯
            'max_workers': max_workers
        }

    except Exception as e:
        logger.error(f"âŒ å¹¶è¡Œæ‰¹é‡æŠ½å–ä»»åŠ¡å¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            'success': False,
            'message': str(e),
            'total': 0,
            'success_count': 0,
            'failed_count': 0,
            'errors': [str(e)]
        }
