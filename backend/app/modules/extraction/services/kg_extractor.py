import json
import yaml
import time
import logging
from typing import List, Dict, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
from openai import OpenAI, APITimeoutError
import tiktoken

# å°è¯•å¯¼å…¥zhipuaiï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ç½®ä¸ºNone
try:
    from zhipuai import ZhipuAI
    ZHIPUAI_AVAILABLE = True
except ImportError:
    ZhipuAI = None
    ZHIPUAI_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class EvidenceSpan:
    """è¯æ®ç‰‡æ®µä½ç½®ä¿¡æ¯"""
    start: int
    end: int
    text: str

    def to_dict(self) -> Dict[str, Any]:
        return {
            'start': self.start,
            'end': self.end,
            'text': self.text
        }

@dataclass
class Attribute:
    """å®ä½“å±æ€§"""
    key: str              # å±æ€§å
    value: str            # å±æ€§å€¼
    value_type: str       # æ•°å€¼/æ–‡æœ¬/æšä¸¾/å¸ƒå°”
    unit: str = ""        # å•ä½
    confidence: float = 1.0
    evidence: str = ""
    evidence_spans: List[EvidenceSpan] = field(default_factory=list)
    is_key_in_config: bool = True  # å±æ€§åæ˜¯å¦åœ¨é…ç½®ä¸­

    def to_dict(self) -> Dict[str, Any]:
        return {
            'key': self.key,
            'value': self.value,
            'value_type': self.value_type,
            'unit': self.unit,
            'confidence': self.confidence,
            'evidence': self.evidence,
            'evidence_spans': [span.to_dict() for span in self.evidence_spans],
            'is_key_in_config': self.is_key_in_config
        }

@dataclass
class Entity:
    """å®ä½“"""
    name: str
    entity_type: str
    attributes: List[Attribute] = field(default_factory=list)
    source_url: str = ""
    doc_id: str = ""
    is_type_in_config: bool = True

    def to_dict(self) -> Dict[str, Any]:
        return {
            'name': self.name,
            'entity_type': self.entity_type,
            'attributes': [attr.to_dict() for attr in self.attributes],
            'source_url': self.source_url,
            'doc_id': self.doc_id,
            'is_type_in_config': self.is_type_in_config
        }

@dataclass
class Relation:
    """å…³ç³»ï¼ˆåŸTripletï¼‰"""
    subject: str
    subject_type: str
    relation: str
    object: str
    object_type: str
    confidence: float
    evidence: str
    evidence_spans: List[EvidenceSpan]
    source_url: str = ""
    doc_id: str = ""
    is_relation_in_config: bool = True
    is_subject_type_in_config: bool = True
    is_object_type_in_config: bool = True

    def to_dict(self) -> Dict[str, Any]:
        return {
            'subject': self.subject,
            'subject_type': self.subject_type,
            'relation': self.relation,
            'object': self.object,
            'object_type': self.object_type,
            'confidence': self.confidence,
            'evidence': self.evidence,
            'evidence_spans': [span.to_dict() for span in self.evidence_spans],
            'source_url': self.source_url,
            'doc_id': self.doc_id,
            'is_relation_in_config': self.is_relation_in_config,
            'is_subject_type_in_config': self.is_subject_type_in_config,
            'is_object_type_in_config': self.is_object_type_in_config
        }

# ä¿ç•™Tripletä½œä¸ºRelationçš„åˆ«åï¼Œç”¨äºå‘åå…¼å®¹
Triplet = Relation

@dataclass
class ExtractionResult:
    """æŠ½å–ç»“æœæ•°æ®ç»“æ„"""
    text: str
    entities: List[Entity]          # æ–°å¢ï¼šå®ä½“åˆ—è¡¨
    relations: List[Relation]       # æ–°å¢ï¼šå…³ç³»åˆ—è¡¨
    triplets: List[Relation] = None # ä¿ç•™ç”¨äºå‘åå…¼å®¹
    processing_time: float = 0.0
    token_usage: Optional[Dict[str, int]] = None

    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼štripletsæŒ‡å‘relationsç”¨äºå‘åå…¼å®¹"""
        if self.triplets is None:
            self.triplets = self.relations

class KnowledgeGraphExtractor:
    """çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æŠ½å–å™¨"""

    def __init__(self, config_path: str):
        """åˆå§‹åŒ–æŠ½å–å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)

        # æ£€æµ‹æ¨¡å‹æä¾›å•†
        self.model_provider = self._detect_model_provider()

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = self._init_llm_client()
        self.tokenizer = self._init_tokenizer()

        # è§£ææ–°çš„é…ç½®æ ¼å¼
        self.entity_types = self._parse_entity_types()
        self.relation_types = self._parse_relation_types()
        self.entity_types_list = list(self.entity_types.keys())
        self.relation_types_list = list(self.relation_types.keys())

        # è§£æå®ä½“å±æ€§å®šä¹‰
        self.entity_attributes = self._parse_entity_attributes()

        self.max_text_length = self.config['processing']['max_text_length']
        self.confidence_threshold = self.config['output']['confidence_threshold']

        # JSON Schemaé…ç½®
        json_schema_config = self.config.get('json_schema', {})
        self.json_schema_enabled = json_schema_config.get('enabled', False)
        self.json_schema = json_schema_config.get('schema', None) if self.json_schema_enabled else None

        logger.info(f"åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æŠ½å–å™¨å®Œæˆ (æ¨¡å‹æä¾›å•†: {self.model_provider})")
        logger.info(f"JSON Schemaæ¨¡å¼: {'å¯ç”¨' if self.json_schema_enabled else 'ç¦ç”¨'}")
        logger.info(f"æ”¯æŒçš„å®ä½“ç±»å‹: {self.entity_types_list}")
        logger.info(f"æ”¯æŒçš„å…³ç³»ç±»å‹: {self.relation_types_list}")

        # ç»Ÿè®¡å±æ€§å®šä¹‰æ•°é‡
        total_attrs = sum(len(attrs) for attrs in self.entity_attributes.values())
        logger.info(f"åŠ è½½äº† {total_attrs} ä¸ªå±æ€§å®šä¹‰")

    def _parse_entity_types(self) -> Dict[str, Dict[str, Any]]:
        """è§£æå®ä½“ç±»å‹é…ç½®"""
        entity_config = self.config.get('entity_types', {})

        # å…¼å®¹æ—§æ ¼å¼ï¼ˆåˆ—è¡¨ï¼‰å’Œæ–°æ ¼å¼ï¼ˆå­—å…¸ï¼‰
        if isinstance(entity_config, list):
            return {entity: {"description": entity} for entity in entity_config}
        else:
            return entity_config

    def _parse_relation_types(self) -> Dict[str, Dict[str, Any]]:
        """è§£æå…³ç³»ç±»å‹é…ç½®"""
        relation_config = self.config.get('relation_types', {})

        # å…¼å®¹æ—§æ ¼å¼ï¼ˆåˆ—è¡¨ï¼‰å’Œæ–°æ ¼å¼ï¼ˆå­—å…¸ï¼‰
        if isinstance(relation_config, list):
            return {relation: {"description": relation} for relation in relation_config}
        else:
            return relation_config

    def _parse_entity_attributes(self) -> Dict[str, Dict[str, Any]]:
        """è§£æå®ä½“çš„å±æ€§å®šä¹‰

        Returns:
            {
                "äº§å“å‹å·": {
                    "åˆ¶å†·é‡": {"value_type": "æ•°å€¼", "unit": "W", ...},
                    "èƒ½æ•ˆç­‰çº§": {"value_type": "æšä¸¾", ...}
                },
                ...
            }
        """
        entity_attributes = {}
        entity_config = self.config.get('entity_types', {})

        for entity_type, config in entity_config.items():
            if 'attributes' in config and isinstance(config['attributes'], dict):
                entity_attributes[entity_type] = config['attributes']
            else:
                entity_attributes[entity_type] = {}

        logger.info(f"åŠ è½½äº† {len(entity_attributes)} ä¸ªå®ä½“ç±»å‹çš„å±æ€§å®šä¹‰")
        return entity_attributes

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise

    def _detect_model_provider(self) -> str:
        """æ£€æµ‹æ¨¡å‹æä¾›å•†

        Returns:
            'zhipuai', 'openai', æˆ–å…¶ä»–å…¼å®¹OpenAIçš„æä¾›å•†
        """
        model_config = self.config['model']
        model_name = model_config.get('model_name', '').lower()
        api_base = model_config.get('api_base', '')

        # æ£€æµ‹æ˜¯å¦æ˜¯æ™ºè°±AI
        if 'glm' in model_name or 'bigmodel.cn' in api_base:
            if not ZHIPUAI_AVAILABLE:
                logger.warning("æ£€æµ‹åˆ°GLMæ¨¡å‹ï¼Œä½†zhipuaiåŒ…æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install zhipuai")
                logger.warning("å°†ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼...")
                return 'openai'
            return 'zhipuai'

        # é»˜è®¤ä¸ºOpenAIæˆ–å…¼å®¹æ¥å£
        return 'openai'

    def _init_llm_client(self) -> Union[OpenAI, 'ZhipuAI']:
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒOpenAIå’Œæ™ºè°±AIï¼‰"""
        model_config = self.config['model']

        if self.model_provider == 'zhipuai':
            logger.info(f"ä½¿ç”¨æ™ºè°±AIå®¢æˆ·ç«¯: {model_config['model_name']}")
            client = ZhipuAI(
                api_key=model_config['api_key'],
                timeout=model_config['timeout']
            )
            return client
        else:
            logger.info(f"ä½¿ç”¨OpenAIå…¼å®¹å®¢æˆ·ç«¯: {model_config['model_name']}")
            client = OpenAI(
                api_key=model_config['api_key'],
                base_url=model_config['api_base'],
                timeout=model_config['timeout']
            )
            return client

    def _init_openai_client(self) -> OpenAI:
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        logger.warning("_init_openai_clientå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨_init_llm_client")
        model_config = self.config['model']

        client = OpenAI(
            api_key=model_config['api_key'],
            base_url=model_config['api_base'],
            timeout=model_config['timeout']
        )

        logger.info(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯: {model_config['model_name']}")
        return client

    def _init_tokenizer(self):
        """åˆå§‹åŒ–tokenizerç”¨äºè®¡ç®—tokenæ•°é‡"""
        try:
            model_name = self.config['model']['model_name']
            if 'gpt-4' in model_name.lower():
                return tiktoken.encoding_for_model("gpt-4")
            elif 'gpt-3.5' in model_name.lower():
                return tiktoken.encoding_for_model("gpt-3.5-turbo")
            else:
                return tiktoken.get_encoding("cl100k_base")
        except:
            return tiktoken.get_encoding("cl100k_base")

    def _count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        try:
            return len(self.tokenizer.encode(text))
        except:
            return len(text) // 4

    def _truncate_text(self, text: str) -> str:
        """æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬"""
        token_count = self._count_tokens(text)
        if token_count <= self.max_text_length:
            return text

        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        truncated_text = ""
        current_tokens = 0

        for sentence in sentences:
            sentence_tokens = self._count_tokens(sentence)
            if current_tokens + sentence_tokens > self.max_text_length:
                break
            truncated_text += sentence + "ã€‚"
            current_tokens += sentence_tokens

        logger.warning(f"æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­: {token_count} -> {current_tokens} tokens")
        return truncated_text

    def _build_prompt(self, text: str) -> List[Dict[str, str]]:
        """æ„å»ºæç¤ºè¯"""
        prompts = self.config['prompts']
        advanced = self.config['advanced_techniques']

        messages = []

        # ç³»ç»Ÿæç¤ºè¯
        messages.append({
            "role": "system",
            "content": prompts['system_prompt']
        })

        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_content = ""

        # æ·»åŠ few-shotç¤ºä¾‹
        if advanced.get('enable_few_shot', False):
            user_content += prompts['few_shot_examples'] + "\n\n"

        # æ·»åŠ ä¸»è¦ä»»åŠ¡æç¤º
        task_prompt = prompts['task_prompt']

        # æ„å»ºå®ä½“ç±»å‹æè¿°
        entity_types_desc = self._format_entity_types_desc()
        relation_types_desc = self._format_relation_types_desc()

        # æ›¿æ¢å ä½ç¬¦
        task_prompt = task_prompt.replace('{{entity_types_desc}}', entity_types_desc)
        task_prompt = task_prompt.replace('{{relation_types_desc}}', relation_types_desc)

        user_content += task_prompt + "\n\n"

        # æ·»åŠ å¾…å¤„ç†æ–‡æœ¬
        user_content += f"**å¾…åˆ†ææ–‡æœ¬**ï¼š\n{text}\n\nè¯·å¼€å§‹æŠ½å–å®ä½“ã€å±æ€§å’Œå…³ç³»ï¼š"

        messages.append({
            "role": "user",
            "content": user_content
        })

        return messages

    def _format_entity_types_desc(self) -> str:
        """æ ¼å¼åŒ–å®ä½“ç±»å‹æè¿°ï¼ˆåŒ…å«å±æ€§å®šä¹‰ï¼‰"""
        descriptions = []
        for entity_type, config in self.entity_types.items():
            desc = f"- **{entity_type}**: {config.get('description', '')}"
            if 'examples' in config:
                examples = ', '.join(config['examples'][:3])
                desc += f" (ä¾‹å¦‚: {examples})"

            # æ·»åŠ å±æ€§å®šä¹‰
            if entity_type in self.entity_attributes:
                attrs = self.entity_attributes[entity_type]
                if attrs:
                    attr_list = []
                    for attr_name, attr_config in list(attrs.items())[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                        attr_desc = f"{attr_name}"
                        if 'unit' in attr_config and attr_config['unit']:
                            attr_desc += f"({attr_config['unit']})"
                        attr_list.append(attr_desc)
                    desc += f"\n  å¯æå–å±æ€§: {', '.join(attr_list)}"

            descriptions.append(desc)
        return '\n'.join(descriptions)

    def _format_relation_types_desc(self) -> str:
        """æ ¼å¼åŒ–å…³ç³»ç±»å‹æè¿°"""
        descriptions = []
        for relation_type, config in self.relation_types.items():
            desc = f"- **{relation_type}**: {config.get('description', '')}"

            # æ·»åŠ ç±»å‹çº¦æŸ
            if 'subject_types' in config and 'object_types' in config:
                subject_types = ', '.join(config['subject_types'])
                object_types = ', '.join(config['object_types'])
                desc += f" (ä¸»ä½“ç±»å‹: {subject_types}; å®¢ä½“ç±»å‹: {object_types})"

            if 'examples' in config:
                examples = ', '.join(config['examples'][:2])
                desc += f" ä¾‹å¦‚: {examples}"

            descriptions.append(desc)
        return '\n'.join(descriptions)

    def _get_json_schema_for_api(self) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨äºAPIè°ƒç”¨çš„JSON Schema

        Returns:
            é€‚ç”¨äºOpenAI/GLM APIçš„response_formatå‚æ•°ï¼Œå¦‚æœæœªå¯ç”¨åˆ™è¿”å›None
        """
        if not self.json_schema_enabled or not self.json_schema:
            return None

        # æ„å»ºç¬¦åˆOpenAI Structured Outputsæ ¼å¼çš„schema
        # å‚è€ƒ: https://platform.openai.com/docs/guides/structured-outputs
        # æ³¨æ„ï¼šç”±äº subject_attributes å’Œ object_attributes éœ€è¦æ”¯æŒåŠ¨æ€é”®å€¼å¯¹ï¼Œ
        # æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨ strict modeï¼ˆstrict mode è¦æ±‚æ‰€æœ‰ object éƒ½è®¾ç½® additionalProperties: falseï¼‰
        return {
            "type": "json_schema",
            "json_schema": {
                "name": "knowledge_graph_extraction",
                "description": "ä»æ–‡æœ¬ä¸­æŠ½å–çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„",
                "schema": self.json_schema,
                "strict": False  # ç¦ç”¨ä¸¥æ ¼æ¨¡å¼ä»¥æ”¯æŒåŠ¨æ€å±æ€§
            }
        }

    def _call_llm(self, messages: List[Dict[str, str]]) -> Tuple[str, Optional[Dict[str, int]]]:
        """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
        model_config = self.config['model']
        max_retries = self.config['processing']['max_retries']
        retry_delay = self.config['processing']['retry_delay']

        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        api_params = {
            'model': model_config['model_name'],
            'messages': messages,
            'temperature': model_config['temperature'],
            'max_tokens': model_config['max_tokens']
        }

        # å¦‚æœå¯ç”¨äº†JSON Schemaï¼Œæ·»åŠ response_formatå‚æ•°
        if self.json_schema_enabled:
            response_format = self._get_json_schema_for_api()
            if response_format:
                api_params['response_format'] = response_format
                logger.info("âœ“ å·²å¯ç”¨JSON Schemaç»“æ„åŒ–è¾“å‡ºæ¨¡å¼")

        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨è°ƒç”¨LLM... (å°è¯• {attempt + 1}/{max_retries})")
                response = self.client.chat.completions.create(**api_params)

                # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰errorå­—æ®µï¼ˆæŸäº›APIè¿”å›errorè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼‰
                if hasattr(response, 'error') and response.error:
                    error_msg = response.error.get('message', 'æœªçŸ¥é”™è¯¯')
                    error_code = response.error.get('code', '')
                    error_type = response.error.get('type', '')

                    logger.error("=" * 80)
                    logger.error(f"âŒ APIè¿”å›é”™è¯¯:")
                    logger.error(f"é”™è¯¯æ¶ˆæ¯: {error_msg}")
                    logger.error(f"é”™è¯¯ä»£ç : {error_code}")
                    logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
                    logger.error("=" * 80)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä½™é¢ä¸è¶³
                    is_quota_error = any([
                        'ä½™é¢ä¸è¶³' in error_msg,
                        'insufficient_quota' in error_type.lower(),
                        'quota_not_enough' in error_type.lower(),
                        error_code == '405',
                        'balance' in error_msg.lower() and 'insufficient' in error_msg.lower(),
                    ])

                    if is_quota_error:
                        logger.error("ğŸ›‘ æ£€æµ‹åˆ°ä½™é¢ä¸è¶³ï¼Œåœæ­¢å¤„ç†")
                        logger.error("è¯·å……å€¼åé‡æ–°è¿è¡Œï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­")
                        raise RuntimeError(f"APIä½™é¢ä¸è¶³: {error_msg}")
                    else:
                        raise ValueError(f"APIé”™è¯¯: {error_msg} (code: {error_code}, type: {error_type})")

                # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
                if not response or not hasattr(response, 'choices'):
                    logger.error("âŒ å“åº”å¯¹è±¡æ— æ•ˆæˆ–æ²¡æœ‰choiceså±æ€§")
                    logger.error(f"Response: {response}")
                    raise ValueError("Invalid response structure")

                if not response.choices or len(response.choices) == 0:
                    logger.error("âŒ choicesåˆ—è¡¨ä¸ºç©º")
                    raise ValueError("Empty choices in response")

                if not hasattr(response.choices[0], 'message'):
                    logger.error("âŒ choiceæ²¡æœ‰messageå±æ€§")
                    raise ValueError("No message in choice")

                content = response.choices[0].message.content

                # æ£€æŸ¥content
                if content is None:
                    logger.error("âŒ message.contentä¸ºNone")
                    logger.error(f"Message object: {response.choices[0].message}")
                    raise ValueError("Content is None")

                token_usage = {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens,
                    'total_tokens': response.usage.total_tokens
                } if response.usage else None

                # â­ è¾“å‡ºLLMåŸå§‹å“åº”å†…å®¹
                logger.info("=" * 80)
                logger.info("ğŸ“¥ LLMåŸå§‹å“åº”å†…å®¹:")
                logger.info("=" * 80)
                logger.info(content)
                logger.info("=" * 80)
                if token_usage:
                    logger.info(f"Tokenä½¿ç”¨: prompt={token_usage['prompt_tokens']}, completion={token_usage['completion_tokens']}, total={token_usage['total_tokens']}")
                logger.info("=" * 80)

                return content, token_usage

            except Exception as e:
                error_msg = str(e)
                error_type = type(e).__name__

                logger.error("=" * 80)
                logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})")
                logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")

                # æ£€æµ‹APIè¶…æ—¶é”™è¯¯
                if isinstance(e, APITimeoutError):
                    current_timeout = model_config['timeout']
                    logger.error("â±ï¸ APIè°ƒç”¨è¶…æ—¶ï¼")
                    logger.error(f"å½“å‰è¶…æ—¶è®¾ç½®: {current_timeout}ç§’")
                    logger.error("å»ºè®®:")
                    logger.error(f"  1. å¢åŠ config.yamlä¸­çš„timeoutå€¼ (å½“å‰{current_timeout}ç§’ â†’ å»ºè®®300-600ç§’)")
                    logger.error(f"  2. å‡å°‘max_tokenså‚æ•° (å½“å‰{model_config.get('max_tokens', 'N/A')})")
                    logger.error(f"  3. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
                    logger.error("=" * 80)

                    if attempt < max_retries - 1:
                        logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        logger.error("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè°ƒç”¨")
                        raise

                # æ£€æµ‹APIæ¬ è´¹/ä½™é¢ä¸è¶³é”™è¯¯
                # å¸¸è§çš„æ¬ è´¹é”™è¯¯æ ‡è¯†ï¼š
                # 1. é”™è¯¯æ¶ˆæ¯ä¸­åŒ…å« "ä½™é¢ä¸è¶³"ã€"insufficient_quota"ã€"quota_not_enough"
                # 2. é”™è¯¯æ¶ˆæ¯ä¸­åŒ…å« "balance"ã€"credit"
                is_quota_error = any([
                    'ä½™é¢ä¸è¶³' in error_msg,
                    'insufficient_quota' in error_msg.lower(),
                    'quota_not_enough' in error_msg.lower(),
                    'insufficient funds' in error_msg.lower(),
                    'quota exceeded' in error_msg.lower(),
                    'balance' in error_msg.lower() and 'insufficient' in error_msg.lower(),
                    'out of credit' in error_msg.lower(),
                ])

                if is_quota_error:
                    logger.error("ğŸ›‘ æ£€æµ‹åˆ°APIä½™é¢ä¸è¶³é”™è¯¯ï¼")
                    logger.error("è¯·å……å€¼åé‡æ–°è¿è¡Œï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­")
                    logger.error("=" * 80)
                    raise RuntimeError(f"APIä½™é¢ä¸è¶³: {error_msg}")

                import traceback
                logger.error(f"é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                logger.error("=" * 80)

                if attempt < max_retries - 1:
                    logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    logger.error("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè°ƒç”¨")
                    raise

    def _parse_llm_response(self, response: str) -> List[Triplet]:
        """è§£æLLMè¿”å›çš„ç»“æœ"""
        triplets = []

        try:
            # å°è¯•å¤šç§æ–¹æ³•æå–JSON
            json_str = None

            # æ–¹æ³•1: æå–```json```ä»£ç å—ï¼ˆä½¿ç”¨æ›´å¥å£®çš„æ­£åˆ™ï¼‰
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                logger.info("ä½¿ç”¨æ–¹æ³•1æå–JSON: ```json```ä»£ç å—")
            else:
                # æ–¹æ³•2: æå–ä»»ä½•```ä»£ç å—
                json_match = re.search(r'```\s*([\s\S]*?)\s*```', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                    logger.info("ä½¿ç”¨æ–¹æ³•2æå–JSON: ```ä»£ç å—")
                else:
                    # æ–¹æ³•3: æŸ¥æ‰¾èŠ±æ‹¬å·åŒ…å›´çš„å®Œæ•´JSONå¯¹è±¡ï¼ˆä»ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}ï¼‰
                    # å…ˆæ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ…å«"triplets"çš„JSONå¯¹è±¡
                    start_idx = response.find('{')
                    if start_idx != -1:
                        # ä½¿ç”¨æ ˆæ¥åŒ¹é…æ‹¬å·ï¼Œæ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
                        bracket_count = 0
                        in_string = False
                        escape_next = False
                        end_idx = -1

                        for i in range(start_idx, len(response)):
                            char = response[i]

                            if escape_next:
                                escape_next = False
                                continue

                            if char == '\\':
                                escape_next = True
                                continue

                            if char == '"' and not escape_next:
                                in_string = not in_string
                                continue

                            if not in_string:
                                if char == '{':
                                    bracket_count += 1
                                elif char == '}':
                                    bracket_count -= 1
                                    if bracket_count == 0:
                                        end_idx = i + 1
                                        break

                        if end_idx != -1:
                            json_str = response[start_idx:end_idx]
                            logger.info("ä½¿ç”¨æ–¹æ³•3æå–JSON: æ‹¬å·åŒ¹é…")

                    if not json_str:
                        # æ–¹æ³•4: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                        json_str = response.strip()
                        logger.info("ä½¿ç”¨æ–¹æ³•4æå–JSON: ç›´æ¥è§£ææ•´ä¸ªå“åº”")

            # æ¸…ç†JSONå­—ç¬¦ä¸²
            if json_str:
                # ç§»é™¤å¯èƒ½çš„æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
                json_str = json_str.strip()
                # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤å°¾éšé€—å·
                json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤æ•°ç»„å°¾éšé€—å·

            logger.info(f"æå–çš„JSONå­—ç¬¦ä¸²(å‰500å­—ç¬¦): {json_str[:500] if json_str else 'None'}...")

            if not json_str:
                logger.error("âš ï¸ æ— æ³•ä»å“åº”ä¸­æå–JSON")
                logger.error(f"å®Œæ•´å“åº”å†…å®¹:\n{response}")
                return triplets

            data = json.loads(json_str)
            triplets_count = len(data.get('triplets', []))
            logger.info(f"âœ“ JSONè§£ææˆåŠŸï¼Œå‘ç° {triplets_count} ä¸ªä¸‰å…ƒç»„")

            # å¦‚æœæ²¡æœ‰ä¸‰å…ƒç»„ï¼Œè®°å½•ä¿¡æ¯ï¼ˆè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼‰
            if triplets_count == 0:
                logger.info("â„¹ï¸ æ­¤æ–‡æ¡£æœªæå–åˆ°ä»»ä½•ä¸‰å…ƒç»„ï¼ˆå¯èƒ½æ–‡æ¡£ä¸åŒ…å«ç›¸å…³ä¿¡æ¯ï¼‰")
                return triplets

            for item in data.get('triplets', []):
                # æ£€æŸ¥å…³ç³»å’Œå®ä½“ç±»å‹æ˜¯å¦åœ¨é…ç½®ä¸­
                relation = item.get('relation', '').strip()
                subject_type = item.get('subject_type', '').strip()
                object_type = item.get('object_type', '').strip()

                is_relation_in_config = relation in self.relation_types_list
                is_subject_type_in_config = subject_type in self.entity_types_list
                is_object_type_in_config = object_type in self.entity_types_list

                # è§£æevidence_spans
                evidence_spans = []
                for span_data in item.get('evidence_spans', []):
                    evidence_span = EvidenceSpan(
                        start=span_data.get('start', 0),
                        end=span_data.get('end', 0),
                        text=span_data.get('text', '')
                    )
                    evidence_spans.append(evidence_span)

                triplet = Triplet(
                    subject=item.get('subject', '').strip(),
                    subject_type=subject_type,
                    relation=relation,
                    object=item.get('object', '').strip(),
                    object_type=object_type,
                    confidence=float(item.get('confidence', 0.0)),
                    evidence=item.get('evidence', '').strip(),
                    evidence_spans=evidence_spans,
                    source_url="",  # å°†åœ¨kg_builderä¸­è®¾ç½®
                    is_relation_in_config=is_relation_in_config,
                    is_subject_type_in_config=is_subject_type_in_config,
                    is_object_type_in_config=is_object_type_in_config
                )

                # éªŒè¯ä¸‰å…ƒç»„
                if self._validate_triplet(triplet):
                    triplets.append(triplet)
                else:
                    logger.warning(f"âš ï¸ æ— æ•ˆä¸‰å…ƒç»„è¢«è¿‡æ»¤: ({triplet.subject}, {triplet.relation}, {triplet.object})")

        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
            logger.error(f"å°è¯•è§£æçš„JSONå­—ç¬¦ä¸²:\n{json_str}")
            logger.error(f"å®Œæ•´å“åº”å†…å®¹:\n{response}")

            # å°è¯•ä»å“åº”ä¸­æ‰‹åŠ¨æå–ä¿¡æ¯
            triplets = self._fallback_parse(response)

        except Exception as e:
            logger.error(f"âŒ è§£æLLMå“åº”å¤±è´¥: {e}")
            logger.error(f"å®Œæ•´å“åº”å†…å®¹:\n{response}")

        return triplets

    def _fallback_parse(self, response: str) -> List[Triplet]:
        """å½“JSONè§£æå¤±è´¥æ—¶çš„å¤‡ç”¨è§£ææ–¹æ³•"""
        triplets = []

        try:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–ä¸‰å…ƒç»„ä¿¡æ¯
            lines = response.split('\n')
            current_triplet = {}

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # æŸ¥æ‰¾é”®å€¼å¯¹
                if ':' in line:
                    parts = line.split(':', 1)
                    if len(parts) == 2:
                        key = parts[0].strip().strip('"').strip("'")
                        value = parts[1].strip().strip(',').strip('"').strip("'")

                        if key in ['subject', 'subject_type', 'relation', 'object', 'object_type', 'evidence']:
                            current_triplet[key] = value
                        elif key == 'confidence':
                            try:
                                current_triplet[key] = float(value)
                            except:
                                current_triplet[key] = 0.5

                # å¦‚æœæ”¶é›†åˆ°å®Œæ•´çš„ä¸‰å…ƒç»„ä¿¡æ¯
                if len(current_triplet) >= 6:
                    # æ£€æŸ¥å…³ç³»å’Œå®ä½“ç±»å‹æ˜¯å¦åœ¨é…ç½®ä¸­
                    relation = current_triplet.get('relation', '')
                    subject_type = current_triplet.get('subject_type', '')
                    object_type = current_triplet.get('object_type', '')

                    is_relation_in_config = relation in self.relation_types_list
                    is_subject_type_in_config = subject_type in self.entity_types_list
                    is_object_type_in_config = object_type in self.entity_types_list

                    triplet = Triplet(
                        subject=current_triplet.get('subject', ''),
                        subject_type=subject_type,
                        relation=relation,
                        object=current_triplet.get('object', ''),
                        object_type=object_type,
                        confidence=current_triplet.get('confidence', 0.5),
                        evidence=current_triplet.get('evidence', ''),
                        evidence_spans=[],  # å¤‡ç”¨è§£ææ— æ³•è·å–ä½ç½®ä¿¡æ¯
                        source_url="",
                        is_relation_in_config=is_relation_in_config,
                        is_subject_type_in_config=is_subject_type_in_config,
                        is_object_type_in_config=is_object_type_in_config
                    )

                    if self._validate_triplet(triplet):
                        triplets.append(triplet)

                    current_triplet = {}

            logger.info(f"å¤‡ç”¨è§£ææ–¹æ³•æå–åˆ° {len(triplets)} ä¸ªä¸‰å…ƒç»„")

        except Exception as e:
            logger.error(f"å¤‡ç”¨è§£æä¹Ÿå¤±è´¥: {e}")

        return triplets

    def _validate_triplet(self, triplet: Triplet) -> bool:
        """éªŒè¯ä¸‰å…ƒç»„çš„æœ‰æ•ˆæ€§"""
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        if not all([triplet.subject, triplet.relation, triplet.object]):
            return False

        # æ£€æŸ¥å…³ç³»ç±»å‹ï¼ˆè®°å½•è­¦å‘Šä½†ä¸è¿‡æ»¤ï¼‰
        if triplet.relation not in self.relation_types_list:
            logger.info(f"å‘ç°éé…ç½®å…³ç³»ç±»å‹: {triplet.relation}")

        # æ£€æŸ¥å®ä½“ç±»å‹ï¼ˆè®°å½•è­¦å‘Šä½†ä¸è¿‡æ»¤ï¼‰
        if triplet.subject_type not in self.entity_types_list:
            logger.info(f"å‘ç°éé…ç½®å®ä½“ç±»å‹: {triplet.subject_type}")

        if triplet.object_type not in self.entity_types_list:
            logger.info(f"å‘ç°éé…ç½®å®ä½“ç±»å‹: {triplet.object_type}")

        # æ£€æŸ¥ç½®ä¿¡åº¦
        if triplet.confidence < self.confidence_threshold:
            return False

        return True

    def _self_consistency_check(self, text: str, triplets_list: List[List[Triplet]]) -> List[Triplet]:
        """è‡ªæˆ‘ä¸€è‡´æ€§æ£€æŸ¥ï¼Œé€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„ä¸‰å…ƒç»„"""
        # ç»Ÿè®¡ä¸‰å…ƒç»„å‡ºç°é¢‘ç‡
        triplet_counts = {}

        for triplets in triplets_list:
            for triplet in triplets:
                key = (triplet.subject, triplet.relation, triplet.object)
                if key not in triplet_counts:
                    triplet_counts[key] = {'count': 0, 'triplet': triplet, 'confidences': []}

                triplet_counts[key]['count'] += 1
                triplet_counts[key]['confidences'].append(triplet.confidence)

        # é€‰æ‹©ä¸€è‡´æ€§é«˜çš„ä¸‰å…ƒç»„
        consistent_triplets = []
        consistency_threshold = len(triplets_list) // 2 + 1  # è¶…è¿‡ä¸€åŠ

        for key, data in triplet_counts.items():
            if data['count'] >= consistency_threshold:
                # ä½¿ç”¨å¹³å‡ç½®ä¿¡åº¦
                avg_confidence = sum(data['confidences']) / len(data['confidences'])
                triplet = data['triplet']
                triplet.confidence = avg_confidence
                consistent_triplets.append(triplet)

        logger.info(f"è‡ªæˆ‘ä¸€è‡´æ€§æ£€æŸ¥: {len(consistent_triplets)}/{len(triplet_counts)} ä¸ªä¸‰å…ƒç»„é€šè¿‡")
        return consistent_triplets

    def _derive_entities_from_relations(self, relations: List[Relation]) -> List[Entity]:
        """ä»å…³ç³»åˆ—è¡¨ä¸­æ¨å¯¼å‡ºå®ä½“åˆ—è¡¨

        Args:
            relations: å…³ç³»åˆ—è¡¨

        Returns:
            å®ä½“åˆ—è¡¨ï¼ˆå»é‡åï¼‰
        """
        entity_dict = {}  # ä½¿ç”¨å­—å…¸å»é‡: (name, type) -> Entity

        for relation in relations:
            # å¤„ç†ä¸»å®ä½“
            subject_key = (relation.subject, relation.subject_type)
            if subject_key not in entity_dict:
                entity_dict[subject_key] = Entity(
                    name=relation.subject,
                    entity_type=relation.subject_type,
                    attributes=[],
                    source_url=relation.source_url,
                    doc_id=relation.doc_id,
                    is_type_in_config=relation.is_subject_type_in_config
                )

            # å¤„ç†å®¢å®ä½“
            object_key = (relation.object, relation.object_type)
            if object_key not in entity_dict:
                entity_dict[object_key] = Entity(
                    name=relation.object,
                    entity_type=relation.object_type,
                    attributes=[],
                    source_url=relation.source_url,
                    doc_id=relation.doc_id,
                    is_type_in_config=relation.is_object_type_in_config
                )

        entities = list(entity_dict.values())
        logger.info(f"ä» {len(relations)} ä¸ªå…³ç³»ä¸­æ¨å¯¼å‡º {len(entities)} ä¸ªå»é‡å®ä½“")

        return entities

    def extract_from_text(self, text: str) -> ExtractionResult:
        """ä»å•ä¸ªæ–‡æœ¬ä¸­æŠ½å–å®ä½“å’Œå…³ç³»"""
        start_time = time.time()

        # æˆªæ–­è¿‡é•¿æ–‡æœ¬
        processed_text = self._truncate_text(text)

        # æ„å»ºæç¤ºè¯
        messages = self._build_prompt(processed_text)

        # è‡ªæˆ‘ä¸€è‡´æ€§æ£€æŸ¥
        if self.config['advanced_techniques'].get('enable_self_consistency', False):
            consistency_count = self.config['advanced_techniques']['consistency_count']
            all_triplets = []
            last_error = None

            for i in range(consistency_count):
                logger.info(f"è‡ªæˆ‘ä¸€è‡´æ€§æŠ½å– {i+1}/{consistency_count}")
                try:
                    response, token_usage = self._call_llm(messages)
                    triplets = self._parse_llm_response(response)
                    all_triplets.append(triplets)
                except Exception as e:
                    logger.error(f"è‡ªæˆ‘ä¸€è‡´æ€§æŠ½å–å¤±è´¥: {e}")
                    last_error = e

            if all_triplets:
                final_relations = self._self_consistency_check(processed_text, all_triplets)
            else:
                # æ‰€æœ‰è‡ªæˆ‘ä¸€è‡´æ€§å°è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯
                logger.error(f"æ‰€æœ‰ {consistency_count} æ¬¡è‡ªæˆ‘ä¸€è‡´æ€§æŠ½å–å‡å¤±è´¥")
                if last_error:
                    raise last_error
                else:
                    raise RuntimeError(f"æ‰€æœ‰ {consistency_count} æ¬¡è‡ªæˆ‘ä¸€è‡´æ€§æŠ½å–å‡å¤±è´¥")
        else:
            # å•æ¬¡æŠ½å–
            try:
                response, token_usage = self._call_llm(messages)
                final_relations = self._parse_llm_response(response)
            except Exception as e:
                logger.error(f"æŠ½å–å¤±è´¥: {e}")
                # âš ï¸ é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œä¸æ˜¯é»˜é»˜è¿”å›ç©ºåˆ—è¡¨
                # è¿™æ ·ä¸Šå±‚è°ƒç”¨è€…æ‰èƒ½çŸ¥é“æŠ½å–å¤±è´¥ï¼Œè§¦å‘é‡è¯•æœºåˆ¶
                raise

        # ä»å…³ç³»ä¸­æ¨å¯¼å‡ºå®ä½“
        final_entities = self._derive_entities_from_relations(final_relations)

        processing_time = time.time() - start_time

        logger.info(f"æŠ½å–å®Œæˆ: {len(final_entities)} ä¸ªå®ä½“, {len(final_relations)} ä¸ªå…³ç³», è€—æ—¶: {processing_time:.2f}s")

        return ExtractionResult(
            text=text,
            entities=final_entities,
            relations=final_relations,
            triplets=None,  # å°†ç”±__post_init__è‡ªåŠ¨è®¾ç½®ä¸ºrelations
            processing_time=processing_time,
            token_usage=token_usage
        )