"""
RAG ç´¢å¼•æ„å»ºå™¨
ä» MySQL è¯»å–çˆ¬è™«ç»“æœï¼Œç”Ÿæˆå‘é‡å¹¶å­˜å‚¨åˆ° Chroma
"""

from typing import List, Dict, Any, Optional
from datetime import datetime
import logging
from sqlalchemy import create_engine, select, func
from sqlalchemy.orm import sessionmaker
from tqdm import tqdm
from .embeddings import BGEM3Embeddings
from .vector_store import ChromaVectorStore

logger = logging.getLogger(__name__)


class RAGIndexer:
    """
    RAG ç´¢å¼•æ„å»ºå™¨

    è´Ÿè´£ä» MySQL è¯»å–çˆ¬è™«ç»“æœï¼Œæ‰¹é‡ç”Ÿæˆ embeddingsï¼Œå¹¶å†™å…¥å‘é‡æ•°æ®åº“
    """

    def __init__(
        self,
        mysql_config: Dict[str, Any],
        embedding_config: Dict[str, Any],
        chroma_config: Dict[str, Any],
    ):
        """
        åˆå§‹åŒ–ç´¢å¼•æ„å»ºå™¨

        Args:
            mysql_config: MySQL é…ç½®
            embedding_config: Embedding æ¨¡å‹é…ç½®
            chroma_config: Chroma å‘é‡æ•°æ®åº“é…ç½®
        """
        self.mysql_config = mysql_config
        self.embedding_config = embedding_config
        self.chroma_config = chroma_config

        # ä½¿ç”¨å•ä¾‹ç®¡ç†å™¨è·å–å…±äº«çš„ Embedding å’Œå‘é‡å­˜å‚¨å®ä¾‹
        from .singleton import RAGSingletonManager

        self.embeddings = RAGSingletonManager.get_embeddings(embedding_config)
        self.vector_store = RAGSingletonManager.get_vector_store(chroma_config)

        # åˆå§‹åŒ– MySQL è¿æ¥
        self._engine = None
        self._Session = None

        logger.info("RAG ç´¢å¼•æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨å…±äº«å®ä¾‹ï¼‰")

    def _get_db_session(self):
        """è·å–æ•°æ®åº“ä¼šè¯"""
        if self._engine is None:
            connection_string = (
                f"mysql+pymysql://{self.mysql_config['user']}:{self.mysql_config['password']}"
                f"@{self.mysql_config['host']}:{self.mysql_config['port']}/{self.mysql_config['database']}"
                f"?charset={self.mysql_config.get('charset', 'utf8mb4')}"
            )

            self._engine = create_engine(
                connection_string,
                pool_pre_ping=True,
                echo=False
            )
            self._Session = sessionmaker(bind=self._engine)

        return self._Session()

    def build_index(
        self,
        batch_size: int = 100,
        last_indexed_id: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        æ„å»ºæˆ–æ›´æ–°ç´¢å¼•

        Args:
            batch_size: æ‰¹é‡å¤„ç†å¤§å°
            last_indexed_id: ä¸Šæ¬¡ç´¢å¼•çš„æœ€å¤§IDï¼Œç”¨äºå¢é‡æ›´æ–°

        Returns:
            Dict: æ„å»ºç»“æœç»Ÿè®¡
                {
                    'total_processed': å¤„ç†çš„æ–‡æ¡£æ•°é‡,
                    'total_indexed': æˆåŠŸç´¢å¼•çš„æ–‡æ¡£æ•°é‡,
                    'last_id': æœ€åå¤„ç†çš„æ–‡æ¡£ID,
                    'start_time': å¼€å§‹æ—¶é—´,
                    'end_time': ç»“æŸæ—¶é—´,
                    'duration_seconds': è€—æ—¶ï¼ˆç§’ï¼‰
                }
        """
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ„å»º RAG ç´¢å¼•...")

        session = self._get_db_session()
        total_processed = 0
        total_indexed = 0
        last_id = last_indexed_id or 0

        try:
            # å¯¼å…¥æ¨¡å‹
            from crawl.mysql.models import CrawlResultModel

            # å…ˆç»Ÿè®¡éœ€è¦å¤„ç†çš„æ–‡æ¡£æ€»æ•°
            count_query = select(func.count()).select_from(CrawlResultModel).where(
                CrawlResultModel.id > last_id
            )
            total_count = session.execute(count_query).scalar() or 0

            if total_count == 0:
                logger.info("æ²¡æœ‰éœ€è¦ç´¢å¼•çš„æ–°æ–‡æ¡£")
                return {
                    'total_processed': 0,
                    'total_indexed': 0,
                    'last_id': last_id,
                    'start_time': start_time.isoformat(),
                    'end_time': datetime.now().isoformat(),
                    'duration_seconds': 0,
                }

            logger.info(f"æ‰¾åˆ° {total_count} ä¸ªå¾…ç´¢å¼•æ–‡æ¡£")

            # æŸ¥è¯¢éœ€è¦ç´¢å¼•çš„æ–‡æ¡£
            query = select(CrawlResultModel).where(
                CrawlResultModel.id > last_id
            ).order_by(CrawlResultModel.id)

            # åˆ›å»ºè¿›åº¦æ¡
            pbar = tqdm(
                total=total_count,
                desc="ğŸ“Š ç´¢å¼•æ„å»ºè¿›åº¦",
                unit="docs",
                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
            )

            # åˆ†æ‰¹å¤„ç†
            offset = 0
            batch_num = 0
            while True:
                # è·å–ä¸€æ‰¹æ•°æ®
                batch_query = query.offset(offset).limit(batch_size)
                results = session.execute(batch_query).scalars().all()

                if not results:
                    break  # æ²¡æœ‰æ›´å¤šæ•°æ®

                batch_num += 1
                pbar.set_description(f"ğŸ“Š æ‰¹æ¬¡ {batch_num} (å…± {len(results)} æ¡)")

                # å‡†å¤‡æ–‡æ¡£æ•°æ®
                documents = []
                texts = []

                for result in results:
                    # æ„å»ºç”¨äº embedding çš„æ–‡æœ¬ï¼ˆæ ‡é¢˜ + å†…å®¹ï¼‰
                    title = result.title or ""
                    content = result.content or ""
                    text = f"{title}\n{content}".strip()

                    if not text:
                        logger.debug(f"æ–‡æ¡£ {result.id} å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                        pbar.update(1)
                        continue

                    texts.append(text)
                    documents.append({
                        'id': result.id,
                        'url': result.url,
                        'title': title,
                        'content': content,
                        'crawled_at': result.crawled_at.isoformat() if result.crawled_at else None,
                    })

                    last_id = result.id  # æ›´æ–°æœ€åå¤„ç†çš„ID

                if not texts:
                    offset += batch_size
                    continue

                # ç”Ÿæˆ embeddings
                pbar.set_description(f"ğŸ§  ç”Ÿæˆå‘é‡ (æ‰¹æ¬¡ {batch_num})")
                embeddings = self.embeddings.embed_documents(texts)

                # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
                pbar.set_description(f"ğŸ’¾ å­˜å‚¨å‘é‡ (æ‰¹æ¬¡ {batch_num})")
                doc_ids = self.vector_store.add_documents(
                    documents=documents,
                    embeddings=embeddings,
                )

                total_processed += len(results)
                total_indexed += len(doc_ids)

                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(len(doc_ids))
                pbar.set_postfix({
                    'å·²ç´¢å¼•': total_indexed,
                    'æˆåŠŸç‡': f"{total_indexed/total_processed*100:.1f}%" if total_processed > 0 else "0%"
                })

                offset += batch_size

            # å…³é—­è¿›åº¦æ¡
            pbar.close()

            # æ„å»ºå®Œæˆ
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            result = {
                'total_processed': total_processed,
                'total_indexed': total_indexed,
                'last_id': last_id,
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'duration_seconds': duration,
            }

            logger.info("=" * 60)
            logger.info(f"âœ“ ç´¢å¼•æ„å»ºå®Œæˆï¼")
            logger.info(f"  å¤„ç†æ–‡æ¡£: {total_processed}")
            logger.info(f"  æˆåŠŸç´¢å¼•: {total_indexed}")
            logger.info(f"  æœ€åID: {last_id}")
            logger.info(f"  è€—æ—¶: {duration:.2f} ç§’")
            logger.info("=" * 60)

            return result

        except Exception as e:
            logger.error(f"âœ— ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

        finally:
            session.close()

    def get_index_status(self) -> Dict[str, Any]:
        """
        è·å–ç´¢å¼•çŠ¶æ€

        Returns:
            Dict: ç´¢å¼•çŠ¶æ€ä¿¡æ¯
                {
                    'total_documents': å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£æ•°é‡,
                    'vector_dimension': å‘é‡ç»´åº¦,
                }
        """
        try:
            total_docs = self.vector_store.count()

            return {
                'total_documents': total_docs,
                'vector_dimension': self.embeddings.dimension,
            }

        except Exception as e:
            logger.error(f"âœ— è·å–ç´¢å¼•çŠ¶æ€å¤±è´¥: {e}")
            return {
                'total_documents': 0,
                'vector_dimension': 0,
                'error': str(e)
            }

    def clear_index(self) -> bool:
        """
        æ¸…ç©ºç´¢å¼•

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.warning("âš  æ­£åœ¨æ¸…ç©º RAG ç´¢å¼•...")
        success = self.vector_store.clear()

        if success:
            logger.info("âœ“ ç´¢å¼•å·²æ¸…ç©º")
        else:
            logger.error("âœ— æ¸…ç©ºç´¢å¼•å¤±è´¥")

        return success
